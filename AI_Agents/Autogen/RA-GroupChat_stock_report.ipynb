{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7de0d9-73ec-4240-aa88-bcb9d94a5312",
   "metadata": {},
   "source": [
    "# Teamwork: Planning a stock report\n",
    "\n",
    "In this project, we are going to setup a team of agents and let them determine how to accomplish the task by themsleves. This is a less efficient method than the ones we've previously used, but it's the one that requires the least of involvement on the user's part.\n",
    "\n",
    "In order for the team to be able to work together, we will provide them with a Planner. The Planner agent's role will be to determine which task should be done first and which agent should accomplish it. This means that we should something to the agent's definitions to let other agents know about their role, so that the Planner can determine which agent can do which task.\n",
    "\n",
    "The task we are going to focus on will be writing a blogpost about the stock performance of a specific asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1690f-83cc-4958-8d4f-451d84a211aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_config object to configure our agents\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o\", \n",
    "    \"api_key\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bab49c-5f53-4168-9294-57681d6a53b2",
   "metadata": {},
   "source": [
    "## Agent Team description\n",
    "\n",
    "* **User_proxy or Admin**: to allow the user to comment on the report and ask the writer to refine it.\n",
    "* **Planner**: to determine relevant information needed to complete the task.\n",
    "* **Engineer**: to write code using the defined plan by the planner.\n",
    "* **Executor**: to execute the code written by the engineer.\n",
    "* **Writer**: to write the report.\n",
    "\n",
    "## The task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26144a2e-dffa-4203-b3e3-0a9c18d5ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Write a blogpost about the stock price performance of \"\\\n",
    "\"Nvidia in the past month. Today's date is 2025-04-30.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfb79e-c91f-4257-ae30-a9961825f1b2",
   "metadata": {},
   "source": [
    "## Defining agents\n",
    "\n",
    "### User proxy\n",
    "\n",
    "This agent will allow us to interact with the agents, it can use auto-reply, will have access to LLM config, have Human Input Mode to Always, which will allow us to interact with the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc340e-ea20-422f-a6db-47e71a0371d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"Give the task, and send \"\n",
    "    \"instructions to writer to refine the blog post.\",\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config, \n",
    "    human_input_mode=\"ALWAYS\", # If user does not provide feedback, the LLM will do it for us\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a9f78-c202-489e-a345-97fcbe9baeca",
   "metadata": {},
   "source": [
    "### Planner Agent\n",
    "\n",
    "#### Description\n",
    "\n",
    "Until now, agents had a **system message prompt**, this message is only known to each agent and defines how they should behave.  \n",
    "We are now going to add a **description message**, this message this time is known by other agents to understand this agent's role. This way, other agents, and specifically the Planner, can determine which agent can accomplish which task.\n",
    "\n",
    "Let's define a Planner with a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28b110-6607-4635-b2bd-a3eab414c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = autogen.ConversableAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"Given a task, please determine \"\n",
    "    \"what information is needed to complete the task. \"\n",
    "    \"Please note that the information will all be retrieved using\"\n",
    "    \" Python code. Please only suggest information that can be \"\n",
    "    \"retrieved using Python code. \"\n",
    "    \"After each step is done by others, check the progress and \"\n",
    "    \"instruct the remaining steps. If a step fails, try to \"\n",
    "    \"workaround\",\n",
    "    description=\"Planner. Given a task, determine what \"\n",
    "    \"information is needed to complete the task. \"\n",
    "    \"After each step is done by others, check the progress and \"\n",
    "    \"instruct the remaining steps\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36351b-5515-4dd1-b3ea-249fdf76b149",
   "metadata": {},
   "source": [
    "### Engineer Agent\n",
    "\n",
    "The Engineer agent already has a default system prompt, which is enough for the task we would like it to accomplish, write code.  \n",
    "We are going to add a description message that lets other agents know about its role. Other agents will also know about the name of agents, and in somes cases that might be enough to define their roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7f308-1d95-4375-8660-8b2a96a991da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system msg: Already has a default one because it is a code writer\n",
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"An engineer that writes code based on the plan \"\n",
    "    \"provided by the planner.\",\n",
    ")\n",
    "\n",
    "# Check engineer system prompt message\n",
    "print(engineer.system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488732ab-8937-4541-8f37-ba611fd23c61",
   "metadata": {},
   "source": [
    "### Executor Agent\n",
    "\n",
    "The Executor agent is a code executor. Since there will be several agents exchanging through a group chat and we're unsure in which order that'll happen, we are going to add an argument in the `code_execution_config`, a parameter that specifies that we want this agent to know about the last 3 messages instead of the last one only.\n",
    "\n",
    "The name of the agent in this case is enough to share its role with other agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a29dd-5174-4573-97e6-d5c84246962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = autogen.ConversableAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Execute the code written by the \"\n",
    "    \"engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1ace6-021f-4753-b57d-59b8fb3ba1c3",
   "metadata": {},
   "source": [
    "### Writer Agent\n",
    "\n",
    "This agent is the writer agent who is going to write the report we want as a blogpost. This agent will have a system message and a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dedf8f-c0e9-4755-8b99-e1bb4eb5cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = autogen.ConversableAgent(\n",
    "    name=\"Writer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Writer.\"\n",
    "    \"Please write blogs in markdown format (with relevant titles)\"\n",
    "    \" and put the content in pseudo ```md``` code block. \"\n",
    "    \"You take feedback from the admin and refine your blog.\",\n",
    "    description=\"Writer.\"\n",
    "    \"Write blogs based on the code execution results and take \"\n",
    "    \"feedback from the admin to refine the blog.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36be68-0d40-4871-92e4-3a6059a98eb1",
   "metadata": {},
   "source": [
    "## The group chat\n",
    "\n",
    "We are now going to define the chat, this time, it's going to be a Group Chat. This means we won't define any conversation order other than specifying who is the Manager. We'll just list the agents who'll be taken part in this group chat, and the max number of turns  we allow for it to last:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8711e-408c-4ec6-bc77-531bceba5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, engineer, writer, executor, planner],\n",
    "    messages=[], # No initial message\n",
    "    max_round=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284900-a3b5-429e-9259-3fe1b6f51946",
   "metadata": {},
   "source": [
    "### Group Chat Manager\n",
    "\n",
    "We will now provide this group chat with a Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c25941-40f9-444d-8d34-777306368d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat, \n",
    "    llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59d693-bb85-440e-9002-f4a1814d388c",
   "metadata": {},
   "source": [
    "### Chat initiation\n",
    "\n",
    "Let's now initiate the chat with a message from the User Proxy agent, us, to the manager, giving the task previously defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73838dfc-c09e-490a-9983-a5f48aa5ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat_result = user_proxy.initiate_chat(\n",
    "    manager, # We initiate between user and manager so we can give the task\n",
    "    message=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ddc1a-c1a0-4758-a6d2-85cd5bc3d94d",
   "metadata": {},
   "source": [
    "We will see your agents interact without help from us to accomplish the task. The planner should determine which task should be done in which order and dispatch preparations and execution to the Engieer and Code Executor and then to the Writer to accomplish the task specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb68ac5-02df-4e91-8a9c-4ea2fa6f5176",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Group Chat with constraints\n",
    "\n",
    "In some cases, we might want to constraint exchanges within the chat. That means that we might want to stop some agents from immediately interacting with other agents or the opposite. We can do so by adding an argument to the Group Chat definition.\n",
    "\n",
    "For example, if we want to ensure that the engineer will only interact with the **Executor** or **User proxy** (us), we can specify that.  \n",
    "Here is how we would define such constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee3d61-2d82-4958-9617-842f5518a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, engineer, writer, executor, planner],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    allowed_or_disallowed_speaker_transitions={\n",
    "        user_proxy: [engineer, writer, executor, planner],\n",
    "        engineer: [user_proxy, executor],\n",
    "        writer: [user_proxy, planner],\n",
    "        executor: [user_proxy, engineer, planner],\n",
    "        planner: [user_proxy, engineer, writer],\n",
    "    },\n",
    "    speaker_transitions_type=\"allowed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89759fc-df67-492e-829e-1699c680e790",
   "metadata": {},
   "source": [
    "We can then simply re-start the chat with these constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7734379-35cc-4213-ad7c-cb22f08a2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat, llm_config=llm_config\n",
    ")\n",
    "\n",
    "groupchat_result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=task,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
